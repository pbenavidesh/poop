---
title: "ETS"
author: "PBH"
date: today
format: 
  html:
    embed-resources: true
    toc: true
    code-link: true
    theme: 
      light: minty
      dark: darkly
---

## pkgs

```{r}
#| message: false
library(tidyverse)
library(fpp3)
```

## Ej: Producción de cerveza

Ya habíamos modelado la producción de cerveza utilizando los métodos de referencia:

```{r}
recent_production <- aus_production %>% filter(year(Quarter) >= 1992)
beer_train <- recent_production %>% filter(year(Quarter) <= 2007)

beer_fit <- beer_train %>%
  model(
    Mean = MEAN(Beer),
    `Naïve` = NAIVE(Beer),
    `Seasonal naïve` = SNAIVE(Beer),
    Drift = RW(Beer ~ drift())
  )

beer_fc <- beer_fit %>%
  forecast(h = 10)

beer_fc %>%
  autoplot(recent_production, level = NULL) +
  xlab("Year") + ylab("Megalitres") +
  ggtitle("Forecasts for quarterly beer production") +
  guides(colour=guide_legend(title="Forecast"))
```

Calculando las métricas de error en el **entrenamiento**:

```{r}
beer_accu_train <- accuracy(beer_fit) |> 
  arrange(MAE)
beer_accu_train
```

Nos dice que el modelo que mejor se ajusta en el entrenamiento, de acuerdo al **MAE** es **`{r} beer_accu_train |> select(.model) |> slice(1) |> pull()`**.

Calculamos las métricas de **error de pronóstico**:

```{r}
beer_accu_fc <- beer_fc |> 
  accuracy(recent_production) |> 
  arrange(MAE)

beer_accu_fc
```

Esto nos indica que el modelo que tiene un menor **MAE** en el pronóstico es **`{r} beer_accu_fc |> select(.model) |> slice(1) |> pull()`**.

## Visualización

Graficamos los datos de entrenamiento en niveles y en logaritmos:


```{r}
beer_train |> 
  autoplot(Beer)

beer_train |> 
  autoplot(log(Beer))
```
Hacemos una descomposición de la serie:

```{r}
dcmp <- beer_train |> 
  model(
    STL(log(Beer), robust = TRUE)
  ) 

dcmp |> 
  components() |> 
  autoplot()

dcmp |> 
  components() |> 
  ggplot(aes(x = Quarter, y = season_adjust)) +
  geom_line()

beer_train |> 
  model(
    STL(Beer, robust = TRUE)
  ) |> 
  components() |> 
  autoplot()
```


## Ajuste de modelos

```{r}
beer_fit <- beer_train |> 
  model(
    snaive = SNAIVE(Beer),
    ets_ANA = ETS(Beer ~ error("A") + trend("N") + season("A")),
    ets_AAdA = ETS(Beer ~ error("A") + trend("Ad") + season("A")),
    ets_MAdM = ETS(Beer ~ error("M") + trend("Ad") + season("M")),
    ets_ANA_l = ETS(log(Beer) ~ error("A") + trend("N") + season("A")),
    ets_AAdA_l = ETS(log(Beer) ~ error("A") + trend("Ad") + season("A")),
    ets_MAdM_l = ETS(log(Beer) ~ error("M") + trend("Ad") + season("M")),
    stl_ets_A = decomposition_model(
      STL(log(Beer), robust = TRUE),
      ETS(season_year ~ error("A") + trend("N") + season("A")),
      ETS(season_adjust ~ error("A") + trend("Ad") + season("N"))
    ),
    stl_ets_M = decomposition_model(
      STL(log(Beer), robust = TRUE),
      ETS(season_year ~ error("M") + trend("N") + season("M")),
      ETS(season_adjust ~ error("A") + trend("Ad") + season("N"))
    )
  )

beer_fit
```

Vamos a utilizar el MAPE como métrica de error:

```{r}
accuracy(beer_fit) |> 
  arrange(MAPE)
```

```{r}
beer_fit |> 
  augment() |> 
  features(.innov, ljung_box, lag = 8)
```
```{r}
beer_fit |> 
  select(stl_ets_A) |> 
  gg_tsresiduals()

beer_fit |> 
  select(stl_ets_M) |> 
  gg_tsresiduals()
```
Hacemos los pronósticos para los siguientes 10 periodos (dos años y medio):

```{r}
beer_fc <- beer_fit |> 
  forecast(h = "2 years 6 months")

beer_fc

beer_fc |> 
  autoplot(recent_production, level = NULL, size = 1)

beer_fc |> 
  autoplot(recent_production |> filter_index("2005 Q1" ~ .), level = NULL, size = 1)

beer_fc |> 
  autoplot(recent_production |> filter_index("2005 Q1" ~ .), size = 1) +
  facet_wrap(~ .model, ncol = 3) +
  theme(legend.position = "none")

beer_fc |> 
  filter(.model != "stl_ets_M") |> 
  autoplot(recent_production |> filter_index("2005 Q1" ~ .), size = 1) +
  facet_wrap(~ .model, ncol = 3) +
  theme(legend.position = "none")

beer_fc |> 
  accuracy(recent_production) |> 
  arrange(MAPE)
```

## Pronósticos

Realizaremos un pronóstico hacia el futuro, con el mejor modelo:

```{r}
beer_fut <- recent_production |> 
  model(
    ets_MAdM = ETS(Beer ~ error("M") + trend("Ad") + season("M"))
  ) |> 
  forecast(h = "2 years 6 months")

beer_fut

beer_fut |> 
  autoplot(recent_production)
```












## OTRO

```{r}
beer_fit <- beer_train |> 
  model(
    snaive = SNAIVE(Beer),
    snaive_log = SNAIVE(log(Beer)),
    ets_MNM_log = ETS(log(Beer) ~ error("M") + trend("N") + season("M")),
    ets_MNM = ETS(Beer ~ error("M") + trend("N") + season("M")),
    ets_M_M = ETS(Beer ~ error("M") + season("M")),
    ets_auto = ETS(Beer),
    ets_auto_log = ETS(log(Beer))
  )

beer_fit
```
```{r}
beer_fit |> 
  select(ets_M_M) |> 
  report()

beer_fit |> 
  select(ets_bc_auto) |> 
  report()

beer_fit |> 
  select(ets_auto) |> 
  report()
```

Los modelos `ets_M_M` y `ets_auto` dan el mismo resultado que el modelo que definimos como `ETS_MNM`, y el modelo `ets_bc_auto` da el mismo resultado que el modelo `ets_MNM_bc`. Por lo tanto, vamos a quitarlos:

```{r}
beer_fit <- beer_fit |> 
  select(-c(ets_M_M, ets_auto, ets_auto_log))

beer_fit

accuracy(beer_fit) |> 
  arrange(MAPE)
```


```{r}
#| warning: false

beer_aug <- beer_fit |> 
  augment()

beer_aug

beer_train |> 
  autoplot(Beer, size = 1) + 
  autolayer(beer_aug, .fitted, size = 1) +
  facet_wrap(~.model, ncol = 2) +
  theme(legend.position = "none")
```

```{r}
#| warning: true

beer_fc <- beer_fit |> 
  forecast(h = 10)

beer_fc

beer_fc |> 
  autoplot(recent_production, level = NULL)

beer_fc |> 
  autoplot(recent_production |> filter_index("2005 Q1" ~ .), level = NULL, size = 1)

beer_fc |> 
  autoplot(recent_production |> filter_index("2007 Q1" ~ .), size = 1) +
  facet_wrap(~ .model, ncol = 2)

beer_fc |> 
  accuracy(recent_production) |> 
  arrange(MAPE)
```

## Tarea

Pueden utilizar series de estas tablas:

```{r}
aus_production

us_employment |> 
  distinct(Title)

global_economy
```
